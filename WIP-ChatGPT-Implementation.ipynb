{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7f44269-769f-4dec-b410-a1871290d25b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:17.021587Z",
     "iopub.status.busy": "2024-02-19T21:18:17.020891Z",
     "iopub.status.idle": "2024-02-19T21:18:20.227235Z",
     "shell.execute_reply": "2024-02-19T21:18:20.226899Z",
     "shell.execute_reply.started": "2024-02-19T21:18:17.021557Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "import custom_functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec63ff26-6b6c-46f8-9b21-7cf60b90f6f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:20.228198Z",
     "iopub.status.busy": "2024-02-19T21:18:20.228026Z",
     "iopub.status.idle": "2024-02-19T21:18:20.303995Z",
     "shell.execute_reply": "2024-02-19T21:18:20.303699Z",
     "shell.execute_reply.started": "2024-02-19T21:18:20.228188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-Level Keys in FPATHS dict:\n",
      "dict_keys(['data', 'images', 'metadata', 'eda', 'models', 'results', 'readme'])\n"
     ]
    }
   ],
   "source": [
    "FPATHS = fn.load_filepaths_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a00d7aa-72f8-4faa-8d4c-c637f9a6117b",
   "metadata": {},
   "source": [
    "## Task: Conversational Retreival Agent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804ae15-0000-48ec-afa8-0ee208665169",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Reviewing [official example](https://github.com/hwchase17/conversational-retrieval-agent/blob/master/streamlit.py) of RetreivalAgent on blog post.\n",
    "\n",
    "- [ ] Separate retreival tool creation from agent creation.\n",
    "    - [ ] WIll make it easier to swap out data source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db83af15-3af5-4c6b-901d-503aedc47f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:20.304696Z",
     "iopub.status.busy": "2024-02-19T21:18:20.304538Z",
     "iopub.status.idle": "2024-02-19T21:18:20.330255Z",
     "shell.execute_reply": "2024-02-19T21:18:20.329895Z",
     "shell.execute_reply.started": "2024-02-19T21:18:20.304686Z"
    }
   },
   "outputs": [],
   "source": [
    "# import streamlit as st\n",
    "\n",
    "# # @st.cache_data\n",
    "\n",
    "# ## Adding caching to reduce api usage\n",
    "# from langchain.cache import InMemoryCache\n",
    "# # from langchain.document_loaders import CSVLoader\n",
    "# from langchain_community.document_loaders import CSVLoader\n",
    "# from langchain.globals import set_llm_cache\n",
    "# from langchain.memory import ChatMessageHistory, ConversationBufferMemory\n",
    "# from langchain.prompts import (\n",
    "#     ChatPromptTemplate, PromptTemplate,\n",
    "#     HumanMessagePromptTemplate,\n",
    "#     MessagesPlaceholder,\n",
    "#     SystemMessagePromptTemplate,\n",
    "# )\n",
    "# from langchain.text_splitter import CharacterTextSplitter#, SpacyTextSplitter\n",
    "# from langchain_community.vectorstores import FAISS, Chroma\n",
    "# from langchain_openai.chat_models import ChatOpenAI\n",
    "# from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "# # from langchain_community.embeddings.spacy_embeddings import SpacyEmbeddings\n",
    "\n",
    "# # set_llm_cache(InMemoryCache())\n",
    "\n",
    "# from langchain import hub\n",
    "# from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "# from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eafc9daa-d5e7-4736-b42a-524978fefa13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:20.331725Z",
     "iopub.status.busy": "2024-02-19T21:18:20.331538Z",
     "iopub.status.idle": "2024-02-19T21:18:21.271298Z",
     "shell.execute_reply": "2024-02-19T21:18:21.270971Z",
     "shell.execute_reply.started": "2024-02-19T21:18:20.331708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-Level Keys in FPATHS dict:\n",
      "dict_keys(['data', 'images', 'metadata', 'eda', 'models', 'results', 'readme'])\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import custom_functions as fn\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.callbacks import StreamlitCallbackHandler\n",
    "from langchain.agents import OpenAIFunctionsAgent, AgentExecutor\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "# Memory: agent token buffer used in original example blog post\n",
    "from langchain.agents.openai_functions_agent.agent_token_buffer_memory import AgentTokenBufferMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "FPATHS = fn.load_filepaths_json()\n",
    "fpath_llm_csv = FPATHS['data']['app']['reviews-with-target-for-llm_csv']\n",
    "fpath_db = FPATHS['data']['app']['vector-db_dir']\n",
    "\n",
    "def display_metadata(meta_df,iloc=0, include_details=False):\n",
    "    # product = meta_df.iloc[iloc]\n",
    "    # md = \"#### Product Being Reviewed\"\n",
    "    md = \"\"\n",
    "    md += f'\\n- Product Title:\\n***\\\"{product[\"Title (Raw)\"]}\\\"***'\n",
    "    # md += f\"<p><img src='{product['Product Image']}' width=300px></p>\"\n",
    "    md += f'\\n- Brand: {product[\"Brand\"]}'\n",
    "    md += f\"\\n- Price: {product['Price']}\"\n",
    "    md += f\"\\n- Ranked {product['Rank']} (2018)\"\n",
    "\n",
    "    md += f\"\\n- Categories:\\n    - \"\n",
    "    md += \"; \".join(product['Categories'])\n",
    "    # md += \n",
    "    # md += f\"\\n- Categories:{', '.join(product['Categories'])}\"\n",
    "    \n",
    "    \n",
    "    return md\n",
    "\n",
    "\n",
    "def load_product_info(fpath):\n",
    "    import json\n",
    "    with open(fpath,'r') as f:\n",
    "        product_json = json.load(f)\n",
    "        \n",
    "    product_string = \"Product Info:\\n\"\n",
    "    for k,v in product_json.items():\n",
    "        if k.lower()=='description':\n",
    "            continue\n",
    "        product_string+=f\"\\n{k} = {v}\\n\"\n",
    "        \n",
    "    return product_string\n",
    "\n",
    "@st.cache_resource\n",
    "def load_vector_database(fpath_db, fpath_csv=None, metadata_columns = ['reviewerID'],\n",
    "                         chunk_size=500, use_previous = True,\n",
    "                         delete=False, as_retriever=False, k=8, **retriever_kwargs):\n",
    "    \n",
    "     # Use EMbedding --> embed chunks --> vectors\n",
    "    embedding_func = OpenAIEmbeddings()\n",
    "    \n",
    "    if delete==True:\n",
    "        # Set use_pervious to False\n",
    "        use_previous= False\n",
    "        db = Chroma(persist_directory=fpath_db, \n",
    "           embedding_function=embedding_func)\n",
    "        db.delete_collection()\n",
    "\n",
    "    if use_previous==True:\n",
    "        db =  Chroma(persist_directory=fpath_db, \n",
    "           embedding_function=embedding_func)\n",
    "    else:\n",
    "        if fpath_csv == None:\n",
    "            raise Exception(\"Must pass fpath_csv if use_previous==False or delete==True\")\n",
    "                \n",
    "        # Load Document --> Split into chunks\n",
    "        loader = CSVLoader(fpath_csv,metadata_columns=metadata_columns)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        \n",
    "        db = Chroma.from_documents(docs, embedding_func, persist_directory= fpath_db)\n",
    "        # Use persist to save to disk\n",
    "        db.persist()\n",
    "\n",
    "    if as_retriever:\n",
    "        return db.as_retriever(k=k, **retriever_kwargs)\n",
    "    else:\n",
    "        return db\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4492cc7-f2eb-4eaa-a002-dfe435cead70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:21.272055Z",
     "iopub.status.busy": "2024-02-19T21:18:21.271820Z",
     "iopub.status.idle": "2024-02-19T21:18:22.348731Z",
     "shell.execute_reply": "2024-02-19T21:18:22.348422Z",
     "shell.execute_reply.started": "2024-02-19T21:18:21.272045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt_dl = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fb78cfc-1291-4c1a-b4b7-6eaf1a48c1a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.349304Z",
     "iopub.status.busy": "2024-02-19T21:18:22.349214Z",
     "iopub.status.idle": "2024-02-19T21:18:22.380688Z",
     "shell.execute_reply": "2024-02-19T21:18:22.380360Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.349295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.chat.ChatPromptTemplate"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8215a37f-54dc-4da2-9746-2b6ff14ba5f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.381358Z",
     "iopub.status.busy": "2024-02-19T21:18:22.381250Z",
     "iopub.status.idle": "2024-02-19T21:18:22.412407Z",
     "shell.execute_reply": "2024-02-19T21:18:22.412059Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.381348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_dl.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06db64ef-f338-49cd-be76-29e5fdf87bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.412995Z",
     "iopub.status.busy": "2024-02-19T21:18:22.412894Z",
     "iopub.status.idle": "2024-02-19T21:18:22.446009Z",
     "shell.execute_reply": "2024-02-19T21:18:22.445446Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.412986Z"
    }
   },
   "outputs": [],
   "source": [
    "# k=6\n",
    "# retriever  = fn.load_vector_database( fpath_db,fpath_llm_csv, k=k, use_previous=False, as_retriever=True)#, use_previous=False)\n",
    "# # import custom_functions as fn\n",
    "# from custom_functions.app_functions import load_product_info\n",
    "\n",
    "# product_string = load_product_info(FPATHS['data']['app']['product-metadata-llm_json'])\n",
    "# ## Make retreieval tool\n",
    "# tool = create_retriever_tool(\n",
    "#     retriever,\n",
    "#     \"search_reviews\",\n",
    "#     \"Searches and returns excerpts from Amazon user reviews.\",\n",
    "# )\n",
    "# tools = [tool]\n",
    "\n",
    "#     # Pull starter prompt from langchainhub\n",
    "# # prompt = hub.pull(\"hwchase17/openai-tools-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef81564a-18ba-48f7-9741-e4d8d75eecf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.446822Z",
     "iopub.status.busy": "2024-02-19T21:18:22.446708Z",
     "iopub.status.idle": "2024-02-19T21:18:22.476895Z",
     "shell.execute_reply": "2024-02-19T21:18:22.476507Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.446812Z"
    }
   },
   "outputs": [],
   "source": [
    "# # produt_string = \n",
    "# # # Replace system prompt\n",
    "# template = f\"You are a helpful data analyst for answering questions about what customers said about a specific  Amazon product using only content from use reviews.\"\n",
    "# product_template = f\" Assume all user questions are asking about the content in the user reviews. Note the product metadata is:\\n{product_string}\\n\\n\"\n",
    "# template+=product_template\n",
    "\n",
    "# # template+=\"\\n\\nUse information from the following review documents to answer questions:\"\n",
    "# # qa_prompt_template= \"\\n- Here are the review documents:\\n----------------\\n{agent_scratchpad}\\n\\n\"\n",
    "# qa_prompt_template =\"\"\"Use the following pieces of context (user reviews) to answer the user's question by summarizing the reviews. \n",
    "#         If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{agent_scratchpad}\\n\\n\"\"\"\n",
    "# template+=qa_prompt_template\n",
    "# # print(template)\n",
    "# system_template= "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a38e75-6d66-48b8-82fd-f545faaf1a4e",
   "metadata": {},
   "source": [
    "```python\n",
    "# downloaded from hub\n",
    "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
    " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
    " MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba89babd-7246-43bb-b41b-c4ba6e9e6a4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.480164Z",
     "iopub.status.busy": "2024-02-19T21:18:22.479934Z",
     "iopub.status.idle": "2024-02-19T21:18:22.509846Z",
     "shell.execute_reply": "2024-02-19T21:18:22.509509Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.480144Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# prompt_template = OpenAIFunctionsAgent.create_prompt(\n",
    "#     system_message=SystemMessage(template),\n",
    "#     extra_prompt_messages=[MessagesPlaceholder(variable_name=\"history\")],\n",
    "# )\n",
    "# prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71e5f043-2d4a-49a7-b304-c0aa597f966c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.510328Z",
     "iopub.status.busy": "2024-02-19T21:18:22.510236Z",
     "iopub.status.idle": "2024-02-19T21:18:22.539622Z",
     "shell.execute_reply": "2024-02-19T21:18:22.539260Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.510319Z"
    }
   },
   "outputs": [],
   "source": [
    "# prompt_template.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57f21c48-a413-4fe5-b097-13295b17ff79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.540324Z",
     "iopub.status.busy": "2024-02-19T21:18:22.540212Z",
     "iopub.status.idle": "2024-02-19T21:18:22.569841Z",
     "shell.execute_reply": "2024-02-19T21:18:22.569339Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.540314Z"
    }
   },
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0,streaming=True)\n",
    "# agent = create_openai_tools_agent(llm, tools, prompt_template)\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools,  verbose=True,  #return_intermediate_steps=True,\n",
    "#                                memory=ConversationBufferMemory(memory_key=\"history\",return_messages=True))\n",
    "# agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3ea532c-92cf-49d3-8a9b-42c4eab5d976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.570476Z",
     "iopub.status.busy": "2024-02-19T21:18:22.570374Z",
     "iopub.status.idle": "2024-02-19T21:18:22.600285Z",
     "shell.execute_reply": "2024-02-19T21:18:22.599925Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.570467Z"
    }
   },
   "outputs": [],
   "source": [
    "# memory = AgentTokenBufferMemory(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19e0e230-8996-4f1a-aaf4-4fddf58ecaa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.600835Z",
     "iopub.status.busy": "2024-02-19T21:18:22.600736Z",
     "iopub.status.idle": "2024-02-19T21:18:22.630696Z",
     "shell.execute_reply": "2024-02-19T21:18:22.630375Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.600826Z"
    }
   },
   "outputs": [],
   "source": [
    "# agent_executor.memory.buffer_as_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f51dbaf-2540-45a7-a8a7-68ed7e774b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.631225Z",
     "iopub.status.busy": "2024-02-19T21:18:22.631123Z",
     "iopub.status.idle": "2024-02-19T21:18:22.661396Z",
     "shell.execute_reply": "2024-02-19T21:18:22.661039Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.631215Z"
    }
   },
   "outputs": [],
   "source": [
    "# starter_message = \"Hello, there! Enter your question here and I will check the full reviews database to provide you the best answer.\"\n",
    "# # session_state_messages = [AIMessage(content=starter_message)]\n",
    "# agent_executor.memory.chat_memory.add_ai_message(starter_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0a6f9ba-d564-4038-8f8d-1436a3a6a77d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.661946Z",
     "iopub.status.busy": "2024-02-19T21:18:22.661860Z",
     "iopub.status.idle": "2024-02-19T21:18:22.691937Z",
     "shell.execute_reply": "2024-02-19T21:18:22.691585Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.661938Z"
    }
   },
   "outputs": [],
   "source": [
    "# # session_state_messages.\n",
    "# prompt =\"What is the cooking time?\"\n",
    "\n",
    "# response = agent_executor.invoke(input={'input':prompt})\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48d36823-a570-4e07-a6e2-2d645c98161e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.692584Z",
     "iopub.status.busy": "2024-02-19T21:18:22.692479Z",
     "iopub.status.idle": "2024-02-19T21:18:22.722113Z",
     "shell.execute_reply": "2024-02-19T21:18:22.721808Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.692575Z"
    }
   },
   "outputs": [],
   "source": [
    "# response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bf8804e-1adb-438f-81eb-bc773edf4114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.722690Z",
     "iopub.status.busy": "2024-02-19T21:18:22.722593Z",
     "iopub.status.idle": "2024-02-19T21:18:22.752033Z",
     "shell.execute_reply": "2024-02-19T21:18:22.751678Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.722682Z"
    }
   },
   "outputs": [],
   "source": [
    "# # agent_executor.memory.chat_memory\n",
    "# agent_executor.memory.buffer_as_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ffe8e49-e988-4c49-b82c-994535d6f264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.752582Z",
     "iopub.status.busy": "2024-02-19T21:18:22.752486Z",
     "iopub.status.idle": "2024-02-19T21:18:22.783282Z",
     "shell.execute_reply": "2024-02-19T21:18:22.782879Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.752573Z"
    }
   },
   "outputs": [],
   "source": [
    "## For steramlit try this as raw code, not a function\n",
    "def print_history(agent_executor):\n",
    "\n",
    "    session_state_messages = agent_executor.memory.buffer_as_messages\n",
    "    for msg in session_state_messages:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            # notebook\n",
    "            print(f\"Assistant: {msg.content}\")\n",
    "            # streamlit\n",
    "            # st.chat_message(\"assistant\").write(msg.content)\n",
    "        \n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            # notebook\n",
    "            print(f\"User: {msg.content}\")\n",
    "            # streamlit\n",
    "            # st.chat_message(\"user\").write(msg.content)\n",
    "        print()\n",
    "        # memory.chat_memory.add_message(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d04aae0d-15f1-425c-a87e-439b57be1371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:18:22.783995Z",
     "iopub.status.busy": "2024-02-19T21:18:22.783887Z",
     "iopub.status.idle": "2024-02-19T21:18:22.813291Z",
     "shell.execute_reply": "2024-02-19T21:18:22.812945Z",
     "shell.execute_reply.started": "2024-02-19T21:18:22.783985Z"
    }
   },
   "outputs": [],
   "source": [
    "# print_history(agent_executor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a91bbddb-6c6f-4a43-8c2e-80290b05f90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:24:30.463596Z",
     "iopub.status.busy": "2024-02-19T21:24:30.462754Z",
     "iopub.status.idle": "2024-02-19T21:25:16.455738Z",
     "shell.execute_reply": "2024-02-19T21:25:16.455073Z",
     "shell.execute_reply.started": "2024-02-19T21:24:30.463559Z"
    }
   },
   "outputs": [],
   "source": [
    "## Updated function\n",
    "fpath_llm_csv = FPATHS['data']['app']['reviews-with-target-for-llm_csv']\n",
    "fpath_db = FPATHS['data']['app']['vector-db_dir']\n",
    "\n",
    "# Running one time to delete the database and make fresh\n",
    "retriever  = fn.load_vector_database( fpath_db,fpath_llm_csv, k=8, delete=True)#, use_previous=False)\n",
    "\n",
    "\n",
    "def get_agent(fpath_db=FPATHS['data']['app']['vector-db_dir'], k=8, temperature=0.1, verbose=False):\n",
    "    \n",
    "    ## Make retreieval tool\n",
    "    retriever  = fn.load_vector_database( fpath_db,fpath_llm_csv, k=k, use_previous=True, as_retriever=True)#, use_previous=False)\n",
    "    tool = create_retriever_tool(\n",
    "        retriever,\n",
    "        \"search_reviews\",\n",
    "        \"Searches and returns excerpts from Amazon user reviews.\",\n",
    "    )\n",
    "    tools = [tool]\n",
    "\n",
    "\n",
    "\n",
    "    # Create template with product info\n",
    "    template = f\"You are a helpful data analyst for answering questions about what customers said about a specific  Amazon product using only content from use reviews.\"\n",
    "    from custom_functions.app_functions import load_product_info\n",
    "    product_string = load_product_info(FPATHS['data']['app']['product-metadata-llm_json'])\n",
    "\n",
    "    product_template = f\" Assume all user questions are asking about the content in the user reviews. Note the product metadata is:\\n```{product_string}```\\n\\n\"\n",
    "    template+=product_template\n",
    "    \n",
    "    qa_prompt_template =\"\"\"Use the following pieces of context (user reviews) to answer the user's question by summarizing the reviews. \n",
    "            If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{agent_scratchpad}\\n\\n\"\"\"\n",
    "    template+=qa_prompt_template\n",
    "    \n",
    "    prompt_template = OpenAIFunctionsAgent.create_prompt(\n",
    "        system_message=SystemMessage(template),\n",
    "        extra_prompt_messages=[MessagesPlaceholder(variable_name=\"history\")],\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(prompt_template.messages)\n",
    "        \n",
    "    llm = ChatOpenAI(temperature=temperature,streaming=True)\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt_template)\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools,  verbose=True, #return_intermediate_steps=True,\n",
    "                                   memory=ConversationBufferMemory(memory_key=\"history\",return_messages=True))\n",
    "    return agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb1e10b9-3b8c-48cc-80bc-e8ce10c4d1e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:32:51.892397Z",
     "iopub.status.busy": "2024-02-19T21:32:51.891607Z",
     "iopub.status.idle": "2024-02-19T21:32:51.946679Z",
     "shell.execute_reply": "2024-02-19T21:32:51.945518Z",
     "shell.execute_reply.started": "2024-02-19T21:32:51.892359Z"
    }
   },
   "outputs": [],
   "source": [
    "## Separating the template code to make the rest of the code more modular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "991639c9-989f-4888-8fc8-fd3cfc16017e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:23:33.310484Z",
     "iopub.status.busy": "2024-02-19T21:23:33.310127Z",
     "iopub.status.idle": "2024-02-19T21:23:33.479763Z",
     "shell.execute_reply": "2024-02-19T21:23:33.479390Z",
     "shell.execute_reply.started": "2024-02-19T21:23:33.310469Z"
    }
   },
   "outputs": [],
   "source": [
    "def reset_agent(#fpath_db = FPATHS['data']['app']['vector-db_dir'],\n",
    "                starter_message = \"Hello, there! Enter your question here and I will check the full reviews database to provide you the best answer.\",\n",
    "               get_agent_kws={}):\n",
    "    # fpath_db\n",
    "    agent_exec = get_agent(**get_agent_kws)\n",
    "    agent_exec.memory.chat_memory.add_ai_message(starter_message)\n",
    "    return agent_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0839a322-86f8-4ac6-8aa2-71650d672a66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:23:33.480350Z",
     "iopub.status.busy": "2024-02-19T21:23:33.480250Z",
     "iopub.status.idle": "2024-02-19T21:23:35.265030Z",
     "shell.execute_reply": "2024-02-19T21:23:35.264755Z",
     "shell.execute_reply.started": "2024-02-19T21:23:33.480341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello, there! Enter your question here and I will check the full reviews database to provide you the best answer.\n",
      "\n",
      "CPU times: user 2.05 s, sys: 290 ms, total: 2.34 s\n",
      "Wall time: 1.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Testing Code\n",
    "agent_exec = get_agent()\n",
    "agent_exec = reset_agent()\n",
    "print_history(agent_exec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9a28c-ee26-4458-8680-46f16600e374",
   "metadata": {},
   "source": [
    ">- For more args available as config for agent.invoke:\n",
    ">- https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.config.RunnableConfig.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad5354de-b9d6-41c3-9587-076c5de38c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:25:16.563353Z",
     "iopub.status.busy": "2024-02-19T21:25:16.563162Z",
     "iopub.status.idle": "2024-02-19T21:25:19.835286Z",
     "shell.execute_reply": "2024-02-19T21:25:19.834515Z",
     "shell.execute_reply.started": "2024-02-19T21:25:16.563342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_reviews` with `{'query': 'cook time'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mreview: Follow the directions!: The trick to these is to prepare them exactly as described in the instructions. Boil for two minutes and then dry in a medium hot pan. That resulted in a a nice texture that was enjoyable to eat.\n",
      "stars: 4\n",
      "\n",
      "review: Follow the directions!: The trick to these is to prepare them exactly as described in the instructions. Boil for two minutes and then dry in a medium hot pan. That resulted in a a nice texture that was enjoyable to eat.\n",
      "stars: 4\n",
      "\n",
      "review: Love These: If you want to improve the texture, rinse under cold water, blanch for one minute, then dry with a paper towel, then pan fry for ~5 minutes, then cook in your sauce for at least 2 minutes so they absorb the flavor. Also, I've begun to cut these before eating because they're pretty hard to cut once they're on the plate.\n",
      "stars: 5\u001b[0m\u001b[32;1m\u001b[1;3mThe recommended cook time for the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is to boil for two minutes and then dry in a medium hot pan. Another suggestion is to blanch for one minute, then pan fry for about 5 minutes, and cook in your sauce for at least 2 minutes for better texture and flavor absorption.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'history', 'output', '__run'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"What is the cook time?\"\n",
    "response = agent_exec.invoke(input={'input':input},  include_run_info=True)\n",
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21837271-5c72-4d2a-abaa-a826df47cf79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:29:26.746834Z",
     "iopub.status.busy": "2024-02-19T21:29:26.745327Z",
     "iopub.status.idle": "2024-02-19T21:29:26.797095Z",
     "shell.execute_reply": "2024-02-19T21:29:26.796603Z",
     "shell.execute_reply.started": "2024-02-19T21:29:26.746773Z"
    }
   },
   "outputs": [],
   "source": [
    "# response['__run']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "177f3f23-136e-48e9-bb60-6b0235df0acf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:27:46.518637Z",
     "iopub.status.busy": "2024-02-19T21:27:46.517992Z",
     "iopub.status.idle": "2024-02-19T21:27:46.572494Z",
     "shell.execute_reply": "2024-02-19T21:27:46.572038Z",
     "shell.execute_reply.started": "2024-02-19T21:27:46.518605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The recommended cook time for the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is to boil for two minutes and then dry in a medium hot pan. Another suggestion is to blanch for one minute, then pan fry for about 5 minutes, and cook in your sauce for at least 2 minutes for better texture and flavor absorption.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba3f8a12-2379-4fd6-85ed-d1782f4ff4b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:27:48.977404Z",
     "iopub.status.busy": "2024-02-19T21:27:48.975951Z",
     "iopub.status.idle": "2024-02-19T21:27:49.026914Z",
     "shell.execute_reply": "2024-02-19T21:27:49.026478Z",
     "shell.execute_reply.started": "2024-02-19T21:27:48.977354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello, there! Enter your question here and I will check the full reviews database to provide you the best answer.\n",
      "\n",
      "User: What is the cook time?\n",
      "\n",
      "Assistant: Based on the reviews, the recommended cook time for the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is to boil for two minutes and then dry in a medium hot pan. Another suggestion is to blanch for one minute, then pan fry for about 5 minutes, and cook in your sauce for at least 2 minutes for better texture and flavor absorption.\n",
      "\n",
      "User: What is the cook time?\n",
      "\n",
      "Assistant: The recommended cook time for the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is to boil for two minutes and then dry in a medium hot pan. Another suggestion is to blanch for one minute, then pan fry for about 5 minutes, and cook in your sauce for at least 2 minutes for better texture and flavor absorption.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_history(agent_exec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df8bcd4b-14d7-422b-891b-c14318b8b957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T21:28:21.363780Z",
     "iopub.status.busy": "2024-02-19T21:28:21.363103Z",
     "iopub.status.idle": "2024-02-19T21:28:24.582227Z",
     "shell.execute_reply": "2024-02-19T21:28:24.581263Z",
     "shell.execute_reply.started": "2024-02-19T21:28:21.363744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_reviews` with `{'query': 'cook time'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mreview: Follow the directions!: The trick to these is to prepare them exactly as described in the instructions. Boil for two minutes and then dry in a medium hot pan. That resulted in a a nice texture that was enjoyable to eat.\n",
      "stars: 4\n",
      "\n",
      "review: Follow the directions!: The trick to these is to prepare them exactly as described in the instructions. Boil for two minutes and then dry in a medium hot pan. That resulted in a a nice texture that was enjoyable to eat.\n",
      "stars: 4\n",
      "\n",
      "review: Love These: If you want to improve the texture, rinse under cold water, blanch for one minute, then dry with a paper towel, then pan fry for ~5 minutes, then cook in your sauce for at least 2 minutes so they absorb the flavor. Also, I've begun to cut these before eating because they're pretty hard to cut once they're on the plate.\n",
      "stars: 5\u001b[0m\u001b[32;1m\u001b[1;3mBased on the reviews, the recommended cook time for the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is to boil for two minutes and then dry in a medium hot pan. Another suggestion is to blanch for one minute, then pan fry for about 5 minutes, and cook in your sauce for at least 2 minutes for better texture and flavor absorption.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: Hello, there! Enter your question here and I will check the full reviews database to provide you the best answer.\n",
      "\n",
      "User: What is the cook time?\n",
      "\n",
      "Assistant: Based on the reviews, the recommended cook time for the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is to boil for two minutes and then dry in a medium hot pan. Another suggestion is to blanch for one minute, then pan fry for about 5 minutes, and cook in your sauce for at least 2 minutes for better texture and flavor absorption.\n",
      "\n",
      "User: What is the cook time?\n",
      "\n",
      "Assistant: The recommended cook time for the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is to boil for two minutes and then dry in a medium hot pan. Another suggestion is to blanch for one minute, then pan fry for about 5 minutes, and cook in your sauce for at least 2 minutes for better texture and flavor absorption.\n",
      "\n",
      "User: What is the cook time?\n",
      "\n",
      "Assistant: Based on the reviews, the recommended cook time for the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is to boil for two minutes and then dry in a medium hot pan. Another suggestion is to blanch for one minute, then pan fry for about 5 minutes, and cook in your sauce for at least 2 minutes for better texture and flavor absorption.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RunInfo(run_id=UUID('b4b45619-c592-488d-934d-05785e149a42'))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"What is the cook time?\"\n",
    "response = agent_exec.invoke(input={'input':input}, include_run_info=True)\n",
    "print_history(agent_exec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397af63-357c-47e8-9a73-d52b5ba6f635",
   "metadata": {},
   "source": [
    "## Task: introducing myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a910fda2-a0cc-4434-b756-797060936a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:27.071155Z",
     "iopub.status.busy": "2024-02-16T20:45:27.071057Z",
     "iopub.status.idle": "2024-02-16T20:45:27.096038Z",
     "shell.execute_reply": "2024-02-16T20:45:27.095704Z",
     "shell.execute_reply.started": "2024-02-16T20:45:27.071146Z"
    }
   },
   "outputs": [],
   "source": [
    "############# Q&A with ChatGPT\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.memory import ChatMessageHistory, ConversationSummaryBufferMemory, ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51862c8b-c823-44d3-98cf-5112d15b5e86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:27.096727Z",
     "iopub.status.busy": "2024-02-16T20:45:27.096629Z",
     "iopub.status.idle": "2024-02-16T20:45:29.865894Z",
     "shell.execute_reply": "2024-02-16T20:45:29.865198Z",
     "shell.execute_reply.started": "2024-02-16T20:45:27.096719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af42a579-c97d-49e5-a7b8-983b4d948f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:29.868308Z",
     "iopub.status.busy": "2024-02-16T20:45:29.868096Z",
     "iopub.status.idle": "2024-02-16T20:45:29.904328Z",
     "shell.execute_reply": "2024-02-16T20:45:29.903991Z",
     "shell.execute_reply.started": "2024-02-16T20:45:29.868286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyPDF2._reader.PdfReader at 0x290d3cc10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "fpath_resume = \"app-assets/James Irving Resume 2024.pdf\"\n",
    "data = PdfReader(fpath_resume)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9ec758c-d764-41a6-838d-969af1a3e0cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:29.905074Z",
     "iopub.status.busy": "2024-02-16T20:45:29.904886Z",
     "iopub.status.idle": "2024-02-16T20:45:29.930154Z",
     "shell.execute_reply": "2024-02-16T20:45:29.929808Z",
     "shell.execute_reply.started": "2024-02-16T20:45:29.905062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e059558-4357-4791-95e6-0e55b5667e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:29.930806Z",
     "iopub.status.busy": "2024-02-16T20:45:29.930706Z",
     "iopub.status.idle": "2024-02-16T20:45:29.953200Z",
     "shell.execute_reply": "2024-02-16T20:45:29.952844Z",
     "shell.execute_reply.started": "2024-02-16T20:45:29.930797Z"
    }
   },
   "outputs": [],
   "source": [
    "pages = data.pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c75f488-09fd-4287-99e5-94d716959578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:29.953762Z",
     "iopub.status.busy": "2024-02-16T20:45:29.953666Z",
     "iopub.status.idle": "2024-02-16T20:45:29.976676Z",
     "shell.execute_reply": "2024-02-16T20:45:29.976349Z",
     "shell.execute_reply.started": "2024-02-16T20:45:29.953754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/Type': '/Page', '/Parent': IndirectObject(2, 0, 11019734032), '/Resources': IndirectObject(4, 0, 11019734032), '/Contents': IndirectObject(3, 0, 11019734032), '/MediaBox': [0, 0, 612, 792], '/Annots': IndirectObject(10, 0, 11019734032)}\n"
     ]
    }
   ],
   "source": [
    "page = data.pages[0]\n",
    "print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d71d3e0b-d8bc-49b6-a122-3df1ba2f1635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:29.977392Z",
     "iopub.status.busy": "2024-02-16T20:45:29.977283Z",
     "iopub.status.idle": "2024-02-16T20:45:30.001661Z",
     "shell.execute_reply": "2024-02-16T20:45:30.001331Z",
     "shell.execute_reply.started": "2024-02-16T20:45:29.977382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addTransformation',\n",
       " 'add_transformation',\n",
       " 'annotations',\n",
       " 'artBox',\n",
       " 'artbox',\n",
       " 'bleedBox',\n",
       " 'bleedbox',\n",
       " 'clear',\n",
       " 'clone',\n",
       " 'compressContentStreams',\n",
       " 'compress_content_streams',\n",
       " 'copy',\n",
       " 'createBlankPage',\n",
       " 'create_blank_page',\n",
       " 'cropBox',\n",
       " 'cropbox',\n",
       " 'extractText',\n",
       " 'extract_text',\n",
       " 'extract_xform_text',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'getContents',\n",
       " 'getObject',\n",
       " 'getXmpMetadata',\n",
       " 'get_contents',\n",
       " 'get_object',\n",
       " 'hash_func',\n",
       " 'hash_value',\n",
       " 'hash_value_data',\n",
       " 'images',\n",
       " 'indirect_ref',\n",
       " 'indirect_reference',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'mediaBox',\n",
       " 'mediabox',\n",
       " 'mergePage',\n",
       " 'mergeRotatedPage',\n",
       " 'mergeRotatedScaledPage',\n",
       " 'mergeRotatedScaledTranslatedPage',\n",
       " 'mergeRotatedTranslatedPage',\n",
       " 'mergeScaledPage',\n",
       " 'mergeScaledTranslatedPage',\n",
       " 'mergeTransformedPage',\n",
       " 'mergeTranslatedPage',\n",
       " 'merge_page',\n",
       " 'pdf',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'raw_get',\n",
       " 'readFromStream',\n",
       " 'read_from_stream',\n",
       " 'rotate',\n",
       " 'rotateClockwise',\n",
       " 'rotateCounterClockwise',\n",
       " 'rotate_clockwise',\n",
       " 'rotation',\n",
       " 'scale',\n",
       " 'scaleBy',\n",
       " 'scaleTo',\n",
       " 'scale_by',\n",
       " 'scale_to',\n",
       " 'setdefault',\n",
       " 'transfer_rotation_to_content',\n",
       " 'trimBox',\n",
       " 'trimbox',\n",
       " 'update',\n",
       " 'user_unit',\n",
       " 'values',\n",
       " 'writeToStream',\n",
       " 'write_to_stream',\n",
       " 'xmpMetadata',\n",
       " 'xmp_metadata']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in dir(page) if not i.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab693b0e-17bd-49ce-a3cc-ab76c90bb145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:32.737313Z",
     "iopub.status.busy": "2024-02-16T20:45:32.735868Z",
     "iopub.status.idle": "2024-02-16T20:45:32.780932Z",
     "shell.execute_reply": "2024-02-16T20:45:32.780488Z",
     "shell.execute_reply.started": "2024-02-16T20:45:32.737270Z"
    }
   },
   "outputs": [],
   "source": [
    "# data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ab03e75-6af2-490d-ba1e-faf2ac269a4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:32.945014Z",
     "iopub.status.busy": "2024-02-16T20:45:32.943984Z",
     "iopub.status.idle": "2024-02-16T20:45:32.990748Z",
     "shell.execute_reply": "2024-02-16T20:45:32.990234Z",
     "shell.execute_reply.started": "2024-02-16T20:45:32.944955Z"
    }
   },
   "outputs": [],
   "source": [
    "# first_page = pages[0]\n",
    "# for i,page in enumerate(pages):\n",
    "#     if i==0:\n",
    "#         continue\n",
    "#     else:\n",
    "#         first_page.merge_page(page)\n",
    "        \n",
    "# first_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1e4421c-adc5-4767-b953-8fe21b0f6446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:33.295196Z",
     "iopub.status.busy": "2024-02-16T20:45:33.294475Z",
     "iopub.status.idle": "2024-02-16T20:45:33.347014Z",
     "shell.execute_reply": "2024-02-16T20:45:33.346472Z",
     "shell.execute_reply.started": "2024-02-16T20:45:33.295160Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(first_page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "488258eb-1695-46cc-b910-86826efaf4ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:33.569274Z",
     "iopub.status.busy": "2024-02-16T20:45:33.568465Z",
     "iopub.status.idle": "2024-02-16T20:45:33.835745Z",
     "shell.execute_reply": "2024-02-16T20:45:33.835451Z",
     "shell.execute_reply.started": "2024-02-16T20:45:33.569225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAMES M. IRVING, PH.D. 8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com |  LINKEDIN: james-irving-phd | GITHHUB; https://github.com/jirvingphd  SUMMARY Versatile neuroscience-turned-data scientist with expertise in neuroscience research and a strong foundation in experimental design and cognitive neuroscience. Proven ability to apply advanced data science techniques, including statistical modeling, machine learning, and data visualization, to extract valuable insights from complex datasets. Proficient in Python programming and proven ability to rapidly master new technologies and programming languages, which facilitates effective interdisciplinary collaboration and promotes robust, data-driven decision-making processes. Possesses a keen analytical mindset and problem-solving skills honed through successful transitions between disciplines. Demonstrates commitment to continuous learning and innovation, aiming to address scientific challenges and contribute to transformative advancements in both neuroscience and data science. SKILLS  Data Analysis  Statistical Modeling  Machine Learning  Data Visualization  Experimental Design  Quantitative Research Methods  Time Series Analysis  Signal Processing  Cognitive Neuroscience  Behavioral Analysis  Database Management  Pattern Recognition  Python Programming  Deep Learning  Natural Language Processing  AI/LLM Model Implementation  Adaptive Communication Style  Problem Solving & Critical Thinking EXPERIENCE Curriculum Writer - Data Science  Coding Dojo | Remote | Mar 2023-Jan 2024  Authored and delivered three advanced data science courses covering Time Series Modeling, NLP, and Model Deployment to facilitate skill acquisition for over 100 learners.  Enhanced and extended the curriculum of a 16-week boot camp to a 24-week program, resulting in a 50% increase in instructional depth and engagement.  Developed and implemented Monday.com boards, including public forms and executive-facing Gantt charts, to automate internal workflows and streamline curriculum management, resolving over 100 issues.  Integrated APIs, Web scraping, and Computer Vision (CNNs) into course content, fostering practical skill development and aligning with industry demands in data science and machine learning. Data Science Instructor | Remote November 2021 - March 2023  Achieved outstanding Net Promoter Scores (NPS) exceeding 90% through the delivery of engaging live lectures, demonstrating effective communication and pedagogical skills.  Implemented automated tools for administrative tasks, reducing student onboarding time from 5 hours to a mere 2 minutes, optimizing operational efficiency.  Authored and delivered a highly acclaimed 4-week course with a perfect NPS rating, showcasing expertise in curriculum development and instructional delivery.  Designed and presented over 16 interactive live lectures and code-along projects, significantly enhancing student participation and fostering a dynamic learning environment. Data Science Instructor  Flatiron School | Remote | Oct 2019-Oct 2021  Mentored and supervised 60+ students to successfully transition into data science, achieving a high post-program employment rate.  Led and conducted 90-minute study groups weekly, accumulating over 270 hours of recorded lessons, enhancing student comprehension and engagement.  Spearheaded the development and implementation of the \"Flex\" boot camp program, refining instructional design and delivery methods to meet diverse learning needs. \n",
      "------------------------------------\n",
      " Established three student-progress-tracking Looker dashboards, providing real-time insights into student performance and facilitating timely intervention strategies.  Implemented data-driven approaches to enhance program efficacy, resulting in improved student outcomes and program satisfaction. Laboratory Manager  University of Maryland, School of Medicine | Baltimore, MD | Jul 2017-Aug 2018  Ensured full compliance with regulatory standards as the lab's public representative, achieving a flawless record with all 4 inspections passing without demerits.  Negotiated and finalized a technical hardware contract worth approximately $100,000 with vendors, optimizing procurement processes and ensuring cost-effectiveness.  Managed and administered over 20 TBs of both cloud and local data storage systems, ensuring data accessibility, security, and efficient retrieval.  Successfully overhauled mouse colony management procedures, resulting in a remarkable 60% reduction in housing costs, from approximately $3.8k/month to $1.5k/month, through strategic resource allocation and process optimization. Postdoctoral Research Fellow | Baltimore, MD June 2015 - July 2017  Spearheaded neuroscience research endeavors, employing cutting-edge techniques such as in vivo optogenetics and electrophysiology recordings, resulting in groundbreaking insights into neural functioning in awake and behaving mice.  Developed approximately 30 custom analysis scripts in languages including Matlab, NexScript, MedPC, and Arduino, enhancing data processing capabilities and facilitating comprehensive statistical analyses of large datasets.  Mentored and guided a diverse team comprising 1 postdoc, 2 Ph.D. students, 3 lab techs, and 3 undergraduate volunteers, fostering an environment of collaborative learning and achieving research excellence.  Demonstrated self-directed learning by mastering Matlab programming and independently creating custom-designed analysis programs for large datasets in multiple programming languages, streamlining data interpretation processes and enhancing research efficiency. DATA SCIENCE PROJECTS Amazon Reviews NLP Analysis - GitHub Link Natural Language Processing Analysis, Modeling, and Deployment with Actionable Insights  Designed and deployed a user-centric Streamlit dashboard, integrating live sentiment predictions and interactive analysis of trends to guide strategic decision-making.  Conducted sentiment analysis on over 5 million Amazon Grocery & Gourmet Food reviews, utilizing NLP and machine learning techniques (Logistic Regression, Tf-idf vectorization) to identify key factors affecting customer satisfaction and achieve 95%  accuracy in sentiment classification.  Employed Hugging Face transformers and langchain/ChatGPT within the dashboard for summarization and insights, translating vast consumer feedback into actionable product enhancement strategies. How to Make a Successful Movie  GitHub Link Constructing and analyzing an extensive movie database with machine-learning-based insights + Tableau Dashboard  Engineered a comprehensive MySQL database integrating IMDB and data from TMDB API for data-driven insights.  Designed an interactive Tableau dashboard to communicate findings to stakeholders, enhancing decision-making processes (see GitHub link).  Applied A/B Testing to make informed recommendations on what movies are successful at the box office. How to Spot a Troll  GitHub Link Classifying Russian Troll Tweets vs Authentic Tweets  Conducted EDA on 3M tweets, identifying patterns indicative of non-authentic activity by Russian Troll Farms.  Produced alternative final models - one optimized for speed, one for accuracy. Recidivism Risk Assessment  GitHub Link Classifying which released prisoners in Iowa will return to a life of crime using Next-Gen Gradient Boosted Trees  Built a classification model to predict recidivism risk among released prisoners with over 70% accuracy (via scikit-learn and Catboost).  Researched Iowa's state sentencing guidelines and sentencing enhancements to engineer new numerical features to capture the severity of the crimes committed and the duration of sentences. \n",
      "------------------------------------\n",
      "EDUCATION Data Science (Full-Time)         February 2019 - August 2019 Flatiron School Doctor of Philosophy               August 2009 - May 2015 Neuroscience University of Maryland, Baltimore, MD Bachelor & Master of Science       August 2004 - December 2008         Neuroscience Tulane University, New Orleans, LA PROFESSIONAL SKILLS Programming:  Python & Object-Oriented Programming  SQL (MySQL, SQLAlchemy)  MATLAB  PyPi Package Publishing  HTML / CSS  NexScript programming  MedState Notation  Git/GitHub Data Analysis  Extract, Transform, Load (ETL)  (numpy, pandas),  AB Testing (scipy, statsmodels, GraphPad Prism, SPSS)  Machine Learning (scikit-learn, Keras, Catboost, XGBoost),  Database Administration Software:  Adobe Illustrator  Adobe Photoshop  GraphPad Prism  Microsoft Office (Word, Excel, PowerPoint)  NeuroExplorer  Plexon OfflineSorter  VS Code  Jupyter Notebook/Lab Visualization/Dashboarding  Plotly / Dash  Tableau  Streamlit Deployment  Seaborn / Matplotlib  Looker Natural Language Processing:  nltk   spaCy  Tensorflow  Hugging Face transformers  LangChain \n",
      " \n"
     ]
    }
   ],
   "source": [
    "page_texts = []\n",
    "for page in data.pages:\n",
    "    page_texts.append(page.extract_text())\n",
    "resume_text = \"\\n------------------------------------\\n\".join(page_texts)\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de9256db-2d5e-4449-8f30-878e53ce0c34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:48:21.524649Z",
     "iopub.status.busy": "2024-02-16T20:48:21.523598Z",
     "iopub.status.idle": "2024-02-16T20:48:21.588418Z",
     "shell.execute_reply": "2024-02-16T20:48:21.588028Z",
     "shell.execute_reply.started": "2024-02-16T20:48:21.524592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo-0125\")#\"gpt-3.5-turbo-instruct\")\n",
    "len(encoding.encode(\"tiktoken is great!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c41b8-936d-4c93-9799-28a1d877e215",
   "metadata": {},
   "source": [
    "for  gpt-3.5.turbo-0125, context window is 16,385, returns up to 4096 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "64c8362c-01c1-45e2-8ae9-66888e1967a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:53:27.170045Z",
     "iopub.status.busy": "2024-02-16T20:53:27.169652Z",
     "iopub.status.idle": "2024-02-16T20:53:27.216401Z",
     "shell.execute_reply": "2024-02-16T20:53:27.216022Z",
     "shell.execute_reply.started": "2024-02-16T20:53:27.170020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1657"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(resume_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147851d-c3ee-4804-bfd8-287e19aa8b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b136cdc1-12e8-4927-b3aa-799463cc9a4e",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/langchain-question-answering-agent-over-docs-18e5585bdbd3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eecdaf86-ae0c-4913-ab25-201223db5b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:55:17.673602Z",
     "iopub.status.busy": "2024-02-16T20:55:17.673204Z",
     "iopub.status.idle": "2024-02-16T20:55:17.716976Z",
     "shell.execute_reply": "2024-02-16T20:55:17.716586Z",
     "shell.execute_reply.started": "2024-02-16T20:55:17.673578Z"
    }
   },
   "outputs": [],
   "source": [
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, separator=\"\\n\", chunk_overlap=100)\n",
    "# texts = text_splitter.split_text(resume_text)\n",
    "# len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a781023e-82bf-4730-81eb-c0856f34885a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:31.367761Z",
     "iopub.status.busy": "2024-02-16T21:14:31.367369Z",
     "iopub.status.idle": "2024-02-16T21:14:31.424506Z",
     "shell.execute_reply": "2024-02-16T21:14:31.424165Z",
     "shell.execute_reply.started": "2024-02-16T21:14:31.367736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['context']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "sys_template = \"You are digital AI clone of the person in the attached resume context. Note: you should not make up anything that you do not know about the person. Here is the context:\\n------\\n{context}\\n\\n------\\n\\n Now introcuce yourself.\"\n",
    "sys_message_prompt= SystemMessagePromptTemplate.from_template(sys_template)#, input_variables=['context']),\n",
    "sys_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d81f49-c805-4181-94e1-327a50bae75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5c805b63-a745-4473-84e9-a41c405f3f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:31.727054Z",
     "iopub.status.busy": "2024-02-16T21:14:31.726657Z",
     "iopub.status.idle": "2024-02-16T21:14:31.774501Z",
     "shell.execute_reply": "2024-02-16T21:14:31.774101Z",
     "shell.execute_reply.started": "2024-02-16T21:14:31.727025Z"
    }
   },
   "outputs": [],
   "source": [
    "# # ai_template =  \"Hello, there!\\nIts a pleasure to meet you. My name is {persons_name} and I am a {occupation}. Would you like to learn some more about me?\"\n",
    "# # ai_message_prompt = AIMessagePromptTemplate.from_template(ai_template)# input_variables=['persons_name','occupation'])\n",
    "# # ai_message_prompt \n",
    "\n",
    "# human_template = \"{question}\"\n",
    "# human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "# human_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4537a449-5d07-44c7-8cf0-12e9dd8b855e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:31.931500Z",
     "iopub.status.busy": "2024-02-16T21:14:31.931108Z",
     "iopub.status.idle": "2024-02-16T21:14:31.975927Z",
     "shell.execute_reply": "2024-02-16T21:14:31.975607Z",
     "shell.execute_reply.started": "2024-02-16T21:14:31.931476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='You are digital AI clone of the person in the attached resume context. Note: you should not make up anything that you do not know about the person. Here is the context:\\n------\\n{context}\\n\\n------\\n\\n Now introcuce yourself.'))])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([sys_message_prompt])#, human_message_prompt])\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "962b6d28-2cb4-4c38-ac04-c951583cf801",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:34.699851Z",
     "iopub.status.busy": "2024-02-16T21:14:34.699462Z",
     "iopub.status.idle": "2024-02-16T21:14:34.744498Z",
     "shell.execute_reply": "2024-02-16T21:14:34.744015Z",
     "shell.execute_reply.started": "2024-02-16T21:14:34.699827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['context']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dd321e0e-f6c3-46bc-84e3-a1cf1f8cb214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:34.967339Z",
     "iopub.status.busy": "2024-02-16T21:14:34.966951Z",
     "iopub.status.idle": "2024-02-16T21:14:35.014214Z",
     "shell.execute_reply": "2024-02-16T21:14:35.013887Z",
     "shell.execute_reply.started": "2024-02-16T21:14:34.967315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "request = chat_prompt.format_prompt(context=resume_text).to_messages()\n",
    "len(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "98a984c3-0ff4-4791-869a-0a6a16dbfc10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:35.705994Z",
     "iopub.status.busy": "2024-02-16T21:14:35.705526Z",
     "iopub.status.idle": "2024-02-16T21:14:38.284165Z",
     "shell.execute_reply": "2024-02-16T21:14:38.283229Z",
     "shell.execute_reply.started": "2024-02-16T21:14:35.705969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am a versatile neuroscience-turned-data scientist with a strong background in neuroscience research and expertise in experimental design and cognitive neuroscience. I have a proven track record of applying advanced data science techniques such as statistical modeling, machine learning, and data visualization to extract valuable insights from complex datasets. Proficient in Python programming, I have the ability to quickly adapt to new technologies and programming languages, enabling effective interdisciplinary collaboration and data-driven decision-making processes. My analytical mindset, problem-solving skills, and commitment to continuous learning have allowed me to successfully navigate transitions between disciplines and contribute to transformative advancements in both neuroscience and data science.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=.5, model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(request)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a5f36513-1b90-44af-979b-d58afc114c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:38.293240Z",
     "iopub.status.busy": "2024-02-16T21:14:38.292855Z",
     "iopub.status.idle": "2024-02-16T21:14:38.318984Z",
     "shell.execute_reply": "2024-02-16T21:14:38.318660Z",
     "shell.execute_reply.started": "2024-02-16T21:14:38.293216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am a versatile neuroscience-turned-data scientist with a strong background in neuroscience research and expertise in experimental design and cognitive neuroscience. I have a proven track record of applying advanced data science techniques such as statistical modeling, machine learning, and data visualization to extract valuable insights from complex datasets. Proficient in Python programming, I have the ability to quickly adapt to new technologies and programming languages, enabling effective interdisciplinary collaboration and data-driven decision-making processes. My analytical mindset, problem-solving skills, and commitment to continuous learning have allowed me to successfully navigate transitions between disciplines and contribute to transformative advancements in both neuroscience and data science.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff26950-c278-4fbd-97ea-fedc547868ec",
   "metadata": {},
   "source": [
    "### Using Sequential Chain to summarize resume first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "45d25633-5c17-4298-b597-446035c3abc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:20:30.044885Z",
     "iopub.status.busy": "2024-02-16T21:20:30.044406Z",
     "iopub.status.idle": "2024-02-16T21:20:30.094222Z",
     "shell.execute_reply": "2024-02-16T21:20:30.093870Z",
     "shell.execute_reply.started": "2024-02-16T21:20:30.044860Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9bf74819-63c3-41df-ac4a-5114d4d0856b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:27:20.533525Z",
     "iopub.status.busy": "2024-02-16T21:27:20.532471Z",
     "iopub.status.idle": "2024-02-16T21:27:20.579698Z",
     "shell.execute_reply": "2024-02-16T21:27:20.579148Z",
     "shell.execute_reply.started": "2024-02-16T21:27:20.533465Z"
    }
   },
   "outputs": [],
   "source": [
    "template1 = \"Give a summary of this person's resume as a personal history/narrative:\\n{resume}\"\n",
    "prompt1 = ChatPromptTemplate.from_template(template1)\n",
    "chain_1 = LLMChain(llm=llm,\n",
    "                     prompt=prompt1,\n",
    "                     output_key=\"personal_history\")\n",
    "\n",
    "\n",
    "# template2 = \"\"\n",
    "template2 = \"You are a clone of James Irving from the attached resume. Please introduce yourself to a potential new employer but do not quote the resume. Note: you should not make up anything that you do not know about the person. Here is the context\\n--------\\n{personal_history}:\"\n",
    "prompt2 = ChatPromptTemplate.from_template(template2)\n",
    "chain_2 = LLMChain(llm=llm,\n",
    "                     prompt=prompt2,\n",
    "                     output_key=\"introduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c64cdb31-5f08-4864-965c-d6b037135c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:27:21.333225Z",
     "iopub.status.busy": "2024-02-16T21:27:21.331904Z",
     "iopub.status.idle": "2024-02-16T21:27:21.379819Z",
     "shell.execute_reply": "2024-02-16T21:27:21.379403Z",
     "shell.execute_reply.started": "2024-02-16T21:27:21.333184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialChain(verbose=True, chains=[LLMChain(prompt=ChatPromptTemplate(input_variables=['resume'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['resume'], template=\"Give a summary of this person's resume as a personal history/narrative:\\n{resume}\"))]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x2960525c0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x296053a60>, model_name='gpt-3.5-turbo-0125', temperature=0.5, openai_api_key='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', openai_proxy=''), output_key='personal_history'), LLMChain(prompt=ChatPromptTemplate(input_variables=['personal_history'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['personal_history'], template='You are a clone of James Irving from the attached resume. Please introduce yourself to a potential new employer but do not quote the resume. Note: you should not make up anything that you do not know about the person. Here is the context\\n--------\\n{personal_history}:'))]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x2960525c0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x296053a60>, model_name='gpt-3.5-turbo-0125', temperature=0.5, openai_api_key='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', openai_proxy=''), output_key='introduction')], input_variables=['resume'], output_variables=['personal_history', 'introduction'])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_chain = SequentialChain(chains=[chain_1,chain_2], input_variables=['resume'],\n",
    "                             output_variables=['personal_history','introduction'],\n",
    "                             verbose=True)\n",
    "intro_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "04a21db8-0c01-4048-88fb-6f99e0bbeec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:27:21.881663Z",
     "iopub.status.busy": "2024-02-16T21:27:21.880639Z",
     "iopub.status.idle": "2024-02-16T21:27:30.291339Z",
     "shell.execute_reply": "2024-02-16T21:27:30.290189Z",
     "shell.execute_reply.started": "2024-02-16T21:27:21.881603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=intro_chain.invoke(resume_text)\n",
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "91e1a3db-a99e-49de-a089-d6e945095e4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:27:30.295710Z",
     "iopub.status.busy": "2024-02-16T21:27:30.295064Z",
     "iopub.status.idle": "2024-02-16T21:27:30.332513Z",
     "shell.execute_reply": "2024-02-16T21:27:30.331981Z",
     "shell.execute_reply.started": "2024-02-16T21:27:30.295673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['resume', 'personal_history', 'introduction'])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a88cd64f-9180-4509-bb0a-a86554c14e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:27:30.333493Z",
     "iopub.status.busy": "2024-02-16T21:27:30.333240Z",
     "iopub.status.idle": "2024-02-16T21:27:30.362018Z",
     "shell.execute_reply": "2024-02-16T21:27:30.361537Z",
     "shell.execute_reply.started": "2024-02-16T21:27:30.333475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is James Irving. I am a neuroscience-turned-data scientist with a strong background in experimental design and cognitive neuroscience. I have experience applying advanced data science techniques such as statistical modeling, machine learning, and data visualization to extract valuable insights from complex datasets. I am proficient in Python programming and have a track record of quickly mastering new technologies and programming languages to facilitate effective interdisciplinary collaboration.\n",
      "\n",
      "In my previous roles, I have authored and delivered advanced data science courses, achieved outstanding Net Promoter Scores, and mentored students to successfully transition into data science. I have also managed data storage systems, optimized procedures, and spearheaded neuroscience research endeavors while mentoring a diverse team.\n",
      "\n",
      "I hold a Doctor of Philosophy in Neuroscience and have completed a Data Science program, along with a Bachelor and Master of Science in Neuroscience. My professional skills include programming, data analysis, software, visualization/dashboarding, and natural language processing. I have worked on various data science projects, demonstrating my expertise in applying data science techniques to real-world problems. I am committed to continuous learning and innovation to address scientific challenges and contribute to transformative advancements in both neuroscience and data science.\n"
     ]
    }
   ],
   "source": [
    "print(results['introduction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37501ae4-544b-4a7e-bbc6-9c07d05cc248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:26:02.438541Z",
     "iopub.status.busy": "2024-02-16T21:26:02.437503Z",
     "iopub.status.idle": "2024-02-16T21:26:02.483927Z",
     "shell.execute_reply": "2024-02-16T21:26:02.483500Z",
     "shell.execute_reply.started": "2024-02-16T21:26:02.438479Z"
    }
   },
   "source": [
    "#### Now start a new converastion with this introduction ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cd342ec7-d16d-4c2a-8311-8c23de75dbfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:25:29.990489Z",
     "iopub.status.busy": "2024-02-16T21:25:29.989431Z",
     "iopub.status.idle": "2024-02-16T21:25:30.039864Z",
     "shell.execute_reply": "2024-02-16T21:25:30.039366Z",
     "shell.execute_reply.started": "2024-02-16T21:25:29.990431Z"
    }
   },
   "outputs": [],
   "source": [
    "# AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3174117-cac1-4976-9a00-70ddf7f901ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc5c1713-aef0-4e0e-8196-6feb7f16e8af",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "375777dc-91d9-4329-a7bc-77257b3ab108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:39:06.390479Z",
     "iopub.status.busy": "2024-02-16T21:39:06.388616Z",
     "iopub.status.idle": "2024-02-16T21:39:06.474552Z",
     "shell.execute_reply": "2024-02-16T21:39:06.474168Z",
     "shell.execute_reply.started": "2024-02-16T21:39:06.390418Z"
    }
   },
   "outputs": [],
   "source": [
    "# from langchain.agents import load_tools\n",
    "# # from langchain.agents.initialize impor in\n",
    "# from langchain.agents import AgentType\n",
    "# from langchain_openai.llms import OpenAI\n",
    "\n",
    "# dir(AgentType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b595e5d6-09df-4ec4-8dad-eb8f2edff880",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:39:07.941896Z",
     "iopub.status.busy": "2024-02-16T21:39:07.941147Z",
     "iopub.status.idle": "2024-02-16T21:39:07.992623Z",
     "shell.execute_reply": "2024-02-16T21:39:07.992161Z",
     "shell.execute_reply.started": "2024-02-16T21:39:07.941846Z"
    }
   },
   "outputs": [],
   "source": [
    "# tools = load_tools([\"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6e969c51-396e-4abb-a924-3d1e588e9240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:39:08.974116Z",
     "iopub.status.busy": "2024-02-16T21:39:08.973558Z",
     "iopub.status.idle": "2024-02-16T21:39:09.022871Z",
     "shell.execute_reply": "2024-02-16T21:39:09.022442Z",
     "shell.execute_reply.started": "2024-02-16T21:39:08.974063Z"
    }
   },
   "outputs": [],
   "source": [
    "# agent = initialize_agent(tools, \n",
    "#                          llm, \n",
    "#                          agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "#                          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dc63a0bc-697e-4b70-b675-c352414c7002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:39:10.873712Z",
     "iopub.status.busy": "2024-02-16T21:39:10.873312Z",
     "iopub.status.idle": "2024-02-16T21:39:10.927222Z",
     "shell.execute_reply": "2024-02-16T21:39:10.926639Z",
     "shell.execute_reply.started": "2024-02-16T21:39:10.873687Z"
    }
   },
   "outputs": [],
   "source": [
    "# agent = create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d784f0-898c-43d0-b45d-f841ba758657",
   "metadata": {},
   "source": [
    "# From QA App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053e4fb-094e-4d1d-8a82-d6536b4d6a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9aad6d-a98b-457a-a666-c7a683171537",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fpath_llm_csv = FPATHS['data']['app']['reviews-with-target-for-llm_csv']\n",
    "# fpath_db = FPATHS['data']['app']['vector-db_dir']\n",
    "\n",
    "# db = fn.load_vector_database( fpath_db,fpath_llm_csv, delete=True)#, use_previous=False)\n",
    "\n",
    "def get_agent(fpath_db, k=8, temperature=0.1,\n",
    "             return_messages=True, verbose=False):\n",
    "    \n",
    "    \n",
    "    # import custom_functions as fn\n",
    "    from custom_functions.app_functions import load_product_info\n",
    "    product_string = load_product_info(FPATHS['data']['app']['product-metadata-llm_json'])\n",
    "    ## Make retreieval tool\n",
    "    tool = create_retriever_tool(\n",
    "         db.as_retriever(k=k),\n",
    "        \"search_reviews\",\n",
    "        \"Searches and returns excerpts from Amazon user reviews.\",\n",
    "    )\n",
    "    tools = [tool]\n",
    "\n",
    "    # Pull starter prompt from langchainhub\n",
    "    prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "    # produt_string = \n",
    "    # # Replace system prompt\n",
    "    template = f\"You are a helpful data analyst for answering questions about what customers said about a specific  Amazon product using only content from use reviews.\"\n",
    "    product_template = f\" Assume all user questions are asking about the content in the user reviews. Note the product metadata is:\\n```{product_string}```\\n\\n\"\n",
    "    template+=product_template\n",
    "    \n",
    "    # template+=\"\\n\\nUse information from the following review documents to answer questions:\"\n",
    "    # qa_prompt_template= \"\\n- Here are the review documents:\\n----------------\\n{agent_scratchpad}\\n\\n\"\n",
    "    qa_prompt_template =\"\"\"Use the following pieces of context (user reviews) to answer the user's question by summarizing the reviews. \n",
    "            If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{agent_scratchpad}\\n\\n\"\"\"\n",
    "    template+=qa_prompt_template\n",
    "    # template+=\"Try to infer one based on the review documents, otherwise just say that you don't know, don't try to make up an answer\"\n",
    "\n",
    "    # Replace system prompt\n",
    "    prompt.messages[0] = SystemMessagePromptTemplate.from_template(template)\n",
    "    prompt = ChatPromptTemplate.from_messages(prompt.messages)\n",
    "\n",
    "    if verbose:\n",
    "        print(prompt.messages)\n",
    "        \n",
    "    llm = ChatOpenAI(temperature=temperature)\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, \n",
    "                                   memory=ConversationBufferMemory(return_messages=return_messages))\n",
    "    return agent_executor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
